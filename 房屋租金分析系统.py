"""
æˆ¿å±‹ç§Ÿé‡‘åˆ†æç³»ç»Ÿ v1.0
æ¨¡å—ç»„æˆï¼š
1. æ•°æ®é¢„å¤„ç†æ¨¡å—
2. ç§Ÿé‡‘é¢„æµ‹æ¨¡å‹
3. ç«äº‰åŠ›è¯„åˆ†ç³»ç»Ÿ
4. Streamlitå¯è§†åŒ–æ¨¡å—
"""
import pandas as pd
import numpy as np
import streamlit as st
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error, r2_score
from sklearn.preprocessing import StandardScaler
import joblib

# ======================
# æ¨¡å—1ï¼šæ•°æ®é¢„å¤„ç†
# ======================
def data_preprocessing(df):
    """
    æ•°æ®é¢„å¤„ç†æ­¥éª¤ï¼š
    1. å¤„ç†ç¼ºå¤±å€¼
    2. ç‰¹å¾å·¥ç¨‹
    3. ç¼–ç åˆ†ç±»å˜é‡
    4. è®¡ç®—è¡ç”Ÿå­—æ®µ
    """
    # ç¼ºå¤±å€¼å¤„ç†
    df['å»ºæˆå¹´ä»½'].fillna(df['å»ºæˆå¹´ä»½'].median(), inplace=True)
    df['æˆ¿å±‹å¹´é¾„'] = 2024 - df['å»ºæˆå¹´ä»½']  # è®¡ç®—å®é™…æˆ¿é¾„
    
    # å¸ƒå°”å­—æ®µè½¬æ¢
    bool_cols = ['æœ‰é˜³å°','æœ‰å¨æˆ¿','æœ‰ç”µæ¢¯','æœ‰èŠ±å›­','æ˜¯æ–°å»ºç­‘']
    df[bool_cols] = df[bool_cols].astype(int)
    
    # åˆ†ç±»å˜é‡ç¼–ç 
    cat_cols = ['åŒºåŸŸ1','åŒºåŸŸ2','è¡—é“','æˆ¿å±‹ç±»å‹','å†…é¥°è´¨é‡']
    df = pd.get_dummies(df, columns=cat_cols, drop_first=True)
    
    # æ—¥æœŸå¤„ç†
    df['ä¸Šä¼ æ—¥æœŸ'] = pd.to_datetime(df['ä¸Šä¼ æ—¥æœŸ'])
    df['ä¸Šä¼ æœˆä»½'] = df['ä¸Šä¼ æ—¥æœŸ'].dt.month
    
    # åˆ é™¤æ— å…³å­—æ®µ
    df.drop(['ID','ä¸Šä¼ æ—¥æœŸ','å»ºæˆå¹´ä»½'], axis=1, inplace=True)
    
    return df

# ======================
# æ¨¡å—2ï¼šç§Ÿé‡‘é¢„æµ‹æ¨¡å‹
# ======================
def train_rent_model(df):
    """è®­ç»ƒéšæœºæ£®æ—å›å½’æ¨¡å‹"""
    X = df.drop('æˆ¿å±‹ç§Ÿé‡‘', axis=1)
    y = df['æˆ¿å±‹ç§Ÿé‡‘']
    
    # æ•°æ®æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # æ‹†åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42)
    
    # æ¨¡å‹è®­ç»ƒ
    model = RandomForestRegressor(n_estimators=100, random_state=42)
    model.fit(X_train, y_train)
    
    # æ¨¡å‹è¯„ä¼°
    y_pred = model.predict(X_test)
    print(f"MAE: {mean_absolute_error(y_test, y_pred):.2f}")
    print(f"RÂ²: {r2_score(y_test, y_pred):.2f}")
    
    # ä¿å­˜æ¨¡å‹å’Œé¢„å¤„ç†å¯¹è±¡
    joblib.dump(model, 'rent_model.pkl')
    joblib.dump(scaler, 'scaler.pkl')
    
    return model, scaler

# ======================
# æ¨¡å—3ï¼šç«äº‰åŠ›è¯„åˆ†ç³»ç»Ÿ
# ======================
def calculate_competitiveness(df, model, scaler):
    """è®¡ç®—æˆ¿æºç«äº‰åŠ›å¾—åˆ†"""
    # ç”Ÿæˆé¢„æµ‹ç§Ÿé‡‘
    X = df.drop('æˆ¿å±‹ç§Ÿé‡‘', axis=1)
    X_scaled = scaler.transform(X)
    df['é¢„æµ‹ç§Ÿé‡‘'] = model.predict(X_scaled)
    
    # è®¡ç®—æ€§ä»·æ¯”æŒ‡æ•°
    df['ç§Ÿé‡‘å·®å¼‚ç‡'] = (df['é¢„æµ‹ç§Ÿé‡‘'] - df['æˆ¿å±‹ç§Ÿé‡‘']) / df['é¢„æµ‹ç§Ÿé‡‘']
    
    # ç«äº‰åŠ›è¯„åˆ†å…¬å¼
    df['ç«äº‰åŠ›å¾—åˆ†'] = (
        0.4 * df['ç§Ÿé‡‘å·®å¼‚ç‡'] +
        0.2 * (df['å±…ä½é¢ç§¯'] / df['æˆ¿å±‹ç§Ÿé‡‘']) +
        0.2 * df['å†…é¥°è´¨é‡_ç¼–ç '] +
        0.1 * df['ä¸Šä¼ å›¾ç‰‡æ•°'] +
        0.1 * (df['æœ‰é˜³å°'] + df['æœ‰å¨æˆ¿'] + df['æœ‰ç”µæ¢¯'])
    )
    
    # æ ‡å‡†åŒ–å¾—åˆ†åˆ°0-100åˆ†
    df['ç«äº‰åŠ›å¾—åˆ†'] = (df['ç«äº‰åŠ›å¾—åˆ†'] - df['ç«äº‰åŠ›å¾—åˆ†'].min()
    ) / (df['ç«äº‰åŠ›å¾—åˆ†'].max() - df['ç«äº‰åŠ›å¾—åˆ†'].min()) * 100
    
    return df.sort_values('ç«äº‰åŠ›å¾—åˆ†', ascending=False)

# ======================
# æ¨¡å—4ï¼šStreamlitå¯è§†åŒ–
# ======================
def streamlit_dashboard(df):
    """å¯è§†åŒ–åˆ†æçœ‹æ¿"""
    st.title("ğŸ  æˆ¿æºç«äº‰åŠ›åˆ†æçœ‹æ¿")
    
    # æ•°æ®ç­›é€‰
    selected_area = st.sidebar.selectbox("é€‰æ‹©åŒºåŸŸ", df['åŒºåŸŸ1'].unique())
    filtered_df = df[df['åŒºåŸŸ1'] == selected_area]
    
    # å…³é”®æŒ‡æ ‡å±•ç¤º
    col1, col2, col3 = st.columns(3)
    col1.metric("å¹³å‡ç«äº‰åŠ›å¾—åˆ†", f"{filtered_df['ç«äº‰åŠ›å¾—åˆ†'].mean():.1f}")
    col2.metric("é«˜æ€§ä»·æ¯”æˆ¿æºæ•°", len(filtered_df[filtered_df['ç«äº‰åŠ›å¾—åˆ†'] > 80]))
    col3.metric("å¹³å‡ç§Ÿé‡‘å·®å¼‚ç‡", f"{filtered_df['ç§Ÿé‡‘å·®å¼‚ç‡'].mean():.2%}")
    
    # ç«äº‰åŠ›åˆ†å¸ƒåœ°å›¾
    st.subheader("è¡—é“ç«äº‰åŠ›åˆ†å¸ƒ")
    street_scores = filtered_df.groupby('è¡—é“')['ç«äº‰åŠ›å¾—åˆ†'].mean().sort_values()
    st.bar_chart(street_scores)
    
    # æ•£ç‚¹å›¾åˆ†æ
    st.subheader("ç§Ÿé‡‘ä¸é¢ç§¯å…³ç³»")
    st.scatter_chart(filtered_df, x='å±…ä½é¢ç§¯', y='æˆ¿å±‹ç§Ÿé‡‘', color='ç«äº‰åŠ›å¾—åˆ†')
    
    # æ˜¾ç¤ºé«˜æ€§ä»·æ¯”æˆ¿æº
    st.subheader("ğŸ† é«˜æ€§ä»·æ¯”æˆ¿æºTop10")
    st.dataframe(filtered_df[['è¡—é“', 'æˆ¿å±‹ç§Ÿé‡‘', 'é¢„æµ‹ç§Ÿé‡‘', 'ç«äº‰åŠ›å¾—åˆ†']]
                .sort_values('ç«äº‰åŠ›å¾—åˆ†', ascending=False).head(10))

# ======================
# ä¸»ç¨‹åº
# ======================
if __name__ == "__main__":
    # åŠ è½½æ•°æ®ï¼ˆç¤ºä¾‹è·¯å¾„ï¼‰
    df = pd.read_csv("housing_data.csv")
    
    # æ‰§è¡Œé¢„å¤„ç†
    processed_df = data_preprocessing(df)
    
    # è®­ç»ƒæ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œåå¯ä»¥æ³¨é‡Šæ‰ï¼‰
    # model, scaler = train_rent_model(processed_df)
    
    # åŠ è½½å·²æœ‰æ¨¡å‹
    model = joblib.load('rent_model.pkl')
    scaler = joblib.load('scaler.pkl')
    
    # è®¡ç®—ç«äº‰åŠ›
    scored_df = calculate_competitiveness(processed_df, model, scaler)
    
    # å¯åŠ¨å¯è§†åŒ–
    streamlit_dashboard(scored_df)
